{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Fine-tuning Microsoft PHI3 with Unsloth for Mental Health Chatbot Development\n\n```Phi-3```, is a powerful large language model (LLM) from Microsoft AI, but to truly unlock its potential for specific needs, fine-tuning on custom data is crucial.   \nWe will use ```Unsloth```, a cutting-edge library, to streamline the fine-tuning process of Phi-3 for our unique dataset.\n\n## Unsloth Advantages : \n- Faster Training \n- Lower Memory Footprint \n- Simplified Workflow","metadata":{}},{"cell_type":"markdown","source":"## 1. Install Necessary Libraries","metadata":{}},{"cell_type":"code","source":"!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n!pip install trl peft accelerate bitsandbytes\n!pip install xformers","metadata":{"execution":{"iopub.status.busy":"2024-06-17T11:48:05.696093Z","iopub.execute_input":"2024-06-17T11:48:05.696441Z","iopub.status.idle":"2024-06-17T11:52:00.890375Z","shell.execute_reply.started":"2024-06-17T11:48:05.696413Z","shell.execute_reply":"2024-06-17T11:52:00.889272Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-tp5rdhz2/unsloth_06fa148a8bf64133aff8c8b1d2c5ae42\n  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-tp5rdhz2/unsloth_06fa148a8bf64133aff8c8b1d2c5ae42\n  Resolved https://github.com/unslothai/unsloth.git to commit 64bb8cfd512a9dcd860d21563b624676f7432ec5\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting tyro (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading tyro-0.8.4-py3-none-any.whl.metadata (7.9 kB)\nRequirement already satisfied: transformers>=4.38.2 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.41.2)\nRequirement already satisfied: datasets>=2.16.0 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.19.2)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.3)\nRequirement already satisfied: wheel>=0.42.0 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.42.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.26.4)\nRequirement already satisfied: protobuf<4.0.0 in /opt/conda/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.13.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (14.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.1)\nRequirement already satisfied: requests>=2.32.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\nRequirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.3.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.23.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.38.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2023.12.25)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.38.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.38.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.3)\nRequirement already satisfied: docstring-parser>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.15)\nRequirement already satisfied: typing-extensions>=4.7.0 in /opt/conda/lib/python3.10/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.9.0)\nRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.7.0)\nCollecting shtab>=1.5.6 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.17.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2023.4)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\nDownloading tyro-0.8.4-py3-none-any.whl (102 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m102.4/102.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nBuilding wheels for collected packages: unsloth\n  Building wheel for unsloth (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for unsloth: filename=unsloth-2024.6-py3-none-any.whl size=114794 sha256=dd404b58cb942e7cfaf27e41880b233422b703c8c9d2bde988f2b495c7cdce4d\n  Stored in directory: /tmp/pip-ephem-wheel-cache-qxcx89_e/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\nSuccessfully built unsloth\nInstalling collected packages: unsloth, shtab, tyro\nSuccessfully installed shtab-1.7.1 tyro-0.8.4 unsloth-2024.6\nCollecting trl\n  Downloading trl-0.9.4-py3-none-any.whl.metadata (11 kB)\nCollecting peft\n  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.30.1)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\nRequirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from trl) (2.1.2)\nRequirement already satisfied: transformers>=4.31.0 in /opt/conda/lib/python3.10/site-packages (from trl) (4.41.2)\nRequirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.10/site-packages (from trl) (1.26.4)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from trl) (2.19.2)\nRequirement already satisfied: tyro>=0.5.11 in /opt/conda/lib/python3.10/site-packages (from trl) (0.8.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.3)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.23.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.3.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (2023.12.25)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (0.19.1)\nRequirement already satisfied: docstring-parser>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (0.15)\nRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (13.7.0)\nRequirement already satisfied: shtab>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (1.7.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (14.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (2.2.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (3.9.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (4.0.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.17.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2023.4)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\nDownloading trl-0.9.4-py3-none-any.whl (226 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading peft-0.11.1-py3-none-any.whl (251 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes, trl, peft\nSuccessfully installed bitsandbytes-0.43.1 peft-0.11.1 trl-0.9.4\nCollecting xformers\n  Downloading xformers-0.0.26.post1-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xformers) (1.26.4)\nCollecting torch==2.3.0 (from xformers)\n  Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->xformers) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->xformers) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->xformers) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->xformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->xformers) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->xformers) (2024.3.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0->xformers)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0->xformers)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0->xformers)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0->xformers)\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0->xformers)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0->xformers)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0->xformers)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0->xformers)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0->xformers)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0->xformers)\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0->xformers)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.3.0 (from torch==2.3.0->xformers)\n  Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->xformers)\n  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.3.0->xformers) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.3.0->xformers) (1.3.0)\nDownloading xformers-0.0.26.post1-cp310-cp310-manylinux2014_x86_64.whl (222.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m222.7/222.7 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, xformers\n  Attempting uninstall: torch\n    Found existing installation: torch 2.1.2\n    Uninstalling torch-2.1.2:\n      Successfully uninstalled torch-2.1.2\nSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 torch-2.3.0 triton-2.3.0 xformers-0.0.26.post1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 2. Import Necessary ","metadata":{}},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nimport torch\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments","metadata":{"execution":{"iopub.status.busy":"2024-06-17T11:53:01.571373Z","iopub.execute_input":"2024-06-17T11:53:01.572194Z","iopub.status.idle":"2024-06-17T11:53:29.970367Z","shell.execute_reply.started":"2024-06-17T11:53:01.572160Z","shell.execute_reply":"2024-06-17T11:53:29.969377Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2024-06-17 11:53:15.697419: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-17 11:53:15.697537: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-17 11:53:15.960289: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 3. Load PHI-3 Model \n\n```FastLangModel``` class form Unsloth to load pre-traind PHI-3","metadata":{}},{"cell_type":"code","source":"# set parameters\n\nmax_seq_length = 2048 # Choose any!  It supports auto RoPE Scaling internally!\ndtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\nload_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.","metadata":{"execution":{"iopub.status.busy":"2024-06-17T11:54:06.324034Z","iopub.execute_input":"2024-06-17T11:54:06.325101Z","iopub.status.idle":"2024-06-17T11:54:06.329836Z","shell.execute_reply.started":"2024-06-17T11:54:06.325069Z","shell.execute_reply":"2024-06-17T11:54:06.328958Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"model, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/Phi-3-mini-4k-instruct\",\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n    # token = \"hf_secret_token\", # if using gated models like meta-llama/Llama-2-7b-hf\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T11:54:11.358099Z","iopub.execute_input":"2024-06-17T11:54:11.358893Z","iopub.status.idle":"2024-06-17T11:54:33.153105Z","shell.execute_reply.started":"2024-06-17T11:54:11.358863Z","shell.execute_reply":"2024-06-17T11:54:33.152354Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.16k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16c11b93dd894603ace19638fb2c14c9"}},"metadata":{}},{"name":"stdout","text":"==((====))==  Unsloth: Fast Mistral patching release 2024.6\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\nO^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n\\        /    Bfloat16 = FALSE. Xformers = 0.0.26.post1. FA = False.\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.26G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cca815b7c6e145f198401726e7af5621"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/172 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd2eaaa310fd4bedb64b9cbc97ae92a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/3.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54889402690c4849a10287a377fbef99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e1481356b504e2d9e543e1bb151f531"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"070a37a5f1164e06860c7f80c3f89d7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac4abb7a7d4a406584ae46d1e92fc96c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf58a660458641e2b3d592b9e45f3da0"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 4. Set Up Fine-Tuning Parameters:","metadata":{}},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0, # Supports any, but = 0 is optimized\n    bias = \"none\",    # Supports any, but = \"none\" is optimized\n    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n    random_state = 3407,\n    use_rslora = False,  # Supports rank stabilized LoRA\n    loftq_config = None, # And LoftQ\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T11:54:44.244236Z","iopub.execute_input":"2024-06-17T11:54:44.244771Z","iopub.status.idle":"2024-06-17T11:54:48.642536Z","shell.execute_reply.started":"2024-06-17T11:54:44.244731Z","shell.execute_reply":"2024-06-17T11:54:48.641740Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"Unsloth 2024.6 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 5. Prepare Training Data\n\nDataset : [Dataset]()\nConversation of a Customer Service","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"qgyd2021/e_commerce_customer_service\", \"faq\")","metadata":{"execution":{"iopub.status.busy":"2024-06-17T11:59:59.202010Z","iopub.execute_input":"2024-06-17T11:59:59.202813Z","iopub.status.idle":"2024-06-17T12:00:01.118990Z","shell.execute_reply.started":"2024-06-17T11:59:59.202777Z","shell.execute_reply":"2024-06-17T12:00:01.118187Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/50.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20238edd273a4a379494eb97028d6f31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/65 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4d9cd9b0b9b4273a46c246432631e54"}},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-06-17T12:00:08.835827Z","iopub.execute_input":"2024-06-17T12:00:08.836184Z","iopub.status.idle":"2024-06-17T12:00:08.843618Z","shell.execute_reply.started":"2024-06-17T12:00:08.836157Z","shell.execute_reply":"2024-06-17T12:00:08.842474Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['url', 'question', 'answer', 'label'],\n        num_rows: 65\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"dataset['train'][:2]","metadata":{"execution":{"iopub.status.busy":"2024-06-17T12:01:37.278130Z","iopub.execute_input":"2024-06-17T12:01:37.278494Z","iopub.status.idle":"2024-06-17T12:01:37.285093Z","shell.execute_reply.started":"2024-06-17T12:01:37.278465Z","shell.execute_reply":"2024-06-17T12:01:37.284237Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"{'url': ['https://www.lightinthebox.com/knowledge-base/?page_key=how-to-order&prm=1.34.146.0',\n  'https://www.lightinthebox.com/knowledge-base/?page_key=check-order-PC&prm=1.34.145.0'],\n 'question': ['How to order', 'How do i check my statusï¼Ÿ'],\n 'answer': [\"It is easy to purchase a product you like on Lightinthebox. Please follow the steps below to make a purchase. Enjoy your shopping!\\n\\nStep 1:\\nLog into your Lightinthebox account:\\nSign in/ Register with your email or third-party platform.\\n\\nStep 2:\\nBrowse the products and add product(s) you like to your shopping cart:\\n1. Choose items that you like and select a color, size, and the quantity you would like to purchase.\\n\\nTip: If you're not so sure about sizing, you can always refer to our Size guide.\\n2. Review the item and your selected color, size, and quantity then click ADD TO CART.\\n\\nStep 3:\\nReview your cart:\\n1. After adding all the desired items to your cart, click on the cart icon or a similar symbol to review your order. Check the quantities, sizes, colors, and prices of the products. You can also remove any items or update quantities in the cart.\\n2. When you're ready to checkout, click CHECKOUT.\\n\\nStep 4:\\nFill in your shipping information and save:\\n1. Provide your shipping address, contact details, and any additional information required for the delivery of your order.\\n\\nStep 5:\\nSubmit your order:\\n1. Choose a shipping method.\\n2. Review your order summary. If you have a coupon available, make sure to apply it.\\n3. When you're all ready to place the order, click CONTINUE.\\n4. Select payment method and PURCHASE. Choose your preferred payment method from the available options then submit your order.\\n\\nFollowing these steps should help you successfully place an order on Lightinthebox, we hope you enjoy shopping at Lightinthebox!\\n\",\n  'LightInTheBox makes it easy for everyone to keep track of his/her account.\\n\\nSign into â€œMy Accountâ€ and click on â€œMy Ordersâ€ located at the top right of the initial page.\\n\\nIn â€œMy Ordersâ€, you will be able to view all your orders and current status of each ordered item.\\n\\nOn your order details page, various types of help options will be available based on your order status. Please refer to the table below to learn more about the available options at each stage of your order.\\n\\nIf you experience an issue when checking your order status, please reach out to Customer Support.'],\n 'label': ['MY Orders', 'MY Orders']}"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import DatasetDict\n\ndef concatenate_question_answer(example):\n    question = example[\"question\"].replace(\"\\n\", \" \")\n    answer = example[\"answer\"].replace(\"\\n\", \" \")\n    return {\"text\": \"<Customer>: \" + question + \" <Agent>: \" + answer}\n\n# Assuming 'dataset' is your DatasetDict\ndata = dataset.map(concatenate_question_answer)\n\n# Print the first 5 examples to verify the transformation\ndata['train']['text'][:5]","metadata":{"execution":{"iopub.status.busy":"2024-06-17T12:23:24.041391Z","iopub.execute_input":"2024-06-17T12:23:24.042109Z","iopub.status.idle":"2024-06-17T12:23:24.058747Z","shell.execute_reply.started":"2024-06-17T12:23:24.042078Z","shell.execute_reply":"2024-06-17T12:23:24.057883Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"[\"<Customer>: How to order <Agent>: It is easy to purchase a product you like on Lightinthebox. Please follow the steps below to make a purchase. Enjoy your shopping!  Step 1: Log into your Lightinthebox account: Sign in/ Register with your email or third-party platform.  Step 2: Browse the products and add product(s) you like to your shopping cart: 1. Choose items that you like and select a color, size, and the quantity you would like to purchase.  Tip: If you're not so sure about sizing, you can always refer to our Size guide. 2. Review the item and your selected color, size, and quantity then click ADD TO CART.  Step 3: Review your cart: 1. After adding all the desired items to your cart, click on the cart icon or a similar symbol to review your order. Check the quantities, sizes, colors, and prices of the products. You can also remove any items or update quantities in the cart. 2. When you're ready to checkout, click CHECKOUT.  Step 4: Fill in your shipping information and save: 1. Provide your shipping address, contact details, and any additional information required for the delivery of your order.  Step 5: Submit your order: 1. Choose a shipping method. 2. Review your order summary. If you have a coupon available, make sure to apply it. 3. When you're all ready to place the order, click CONTINUE. 4. Select payment method and PURCHASE. Choose your preferred payment method from the available options then submit your order.  Following these steps should help you successfully place an order on Lightinthebox, we hope you enjoy shopping at Lightinthebox! \",\n '<Customer>: How do i check my statusï¼Ÿ <Agent>: LightInTheBox makes it easy for everyone to keep track of his/her account.  Sign into â€œMy Accountâ€ and click on â€œMy Ordersâ€ located at the top right of the initial page.  In â€œMy Ordersâ€, you will be able to view all your orders and current status of each ordered item.  On your order details page, various types of help options will be available based on your order status. Please refer to the table below to learn more about the available options at each stage of your order.  If you experience an issue when checking your order status, please reach out to Customer Support.',\n '<Customer>: Why i can\\'t find my order in my account? <Agent>: The possible reason that you are unable to see the order in your account has been detected as following:  1.Incorrect user account as logged  There are several ways to order from the LITB store. In other words, it is critical to identify the correct user account in order to locate the order number accordingly.  *Can you receive order notification email? If so, the email address is your login account  *Is it possible that you paid the order directly via PayPal without registration? If so, your PayPal account is the login account You can click \"Forgot password\" to get a new one, or you can search in your email inbox to find out the previous password.  *Did you use Facebook/Google/Mobile Phone to login before? If so, the social account is your login account. You can use the same way to login and you will find your order in the account.  2.Incorrect Merchant Channel as logged  Make sure whether you have placed the order on LightInTheBox.com or MiniInThebox.com. You had better look up the order related email notifications to make it right.  3.User account logged via mobile browser  You want to check status of your paid order as logged via mobile browser, but it is nowhere to be found. As suggested, for more details about orders or shipping, download our App to check all your orders.  Please go visit our website by logging in with your COMPUTER (www.lightinthebox.com) or download the LightInTheBox APP via your phone. Once you login, you will be able to check order status.  If you tried the above solutions but all failed, please click \"Need Help\" to contact Customer support',\n \"<Customer>: Why isn't my package delivered in 5 days since i paid for expedited expressï¼Ÿ <Agent>: Please understand the 3~5 business days is only for shipping via Expedited Express, which does not include the processing time fo the item(s). The Total Delivery Time consists of processing time and shipping time, TWO different parts.  Processing time: is the time it takes to get your order ready to leave our warehouses.  This includes preparing your items, performing quality checks, and packing for shipment. Processing time will be displayed on the product detail page after the size/color etc options have been chosen.  *For Made-To-Measure item: Processing time is simply the Tailoring time displayed on the product detail page.  *For Items marked Ships in 24: Processing time is guaranteed to be shorter than 24 hours.  Shipping time: is the time it takes to reach your destination address after the package is shipped out. It depends on the shipping method you choose. Also it shows business days delivery, so please take weekends into consideration when counting the estimated delivery date.\",\n '<Customer>: Can i rush my orderï¼Ÿ <Agent>: Unfortunately, at this time you are not allowed to rush your order, because we are outsourcing from our global suppliers and all the orders fulfillment are in queue. If you require that your order arrives before a specific day or in case you need products urgently, you should reach out to Customer Support.']"},"metadata":{}}]},{"cell_type":"markdown","source":"### Alternative Solution for formatting prompts to suit for FineTuning(Single Column Text) \n\n```bash \ndataset = dataset.map(formatting_prompts_func, batched = True,)\n```","metadata":{}},{"cell_type":"markdown","source":"## 6. Fine-Tuning with Unsloth:","metadata":{}},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import TrainingArguments\n\ntrainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    train_dataset = data['train'],\n    dataset_text_field = \"text\",\n    max_seq_length = max_seq_length,\n    dataset_num_proc = 2,\n    packing = False, # Can make training 5x faster for short sequences.\n    args = TrainingArguments(\n        per_device_train_batch_size = 2,\n        gradient_accumulation_steps = 4,\n        warmup_steps = 5,\n        max_steps = 60,\n        learning_rate = 2e-4,\n        fp16 = not torch.cuda.is_bf16_supported(),\n        bf16 = torch.cuda.is_bf16_supported(),\n        logging_steps = 1,\n        optim = \"adamw_8bit\",\n        weight_decay = 0.01,\n        lr_scheduler_type = \"linear\",\n        seed = 3407,\n        output_dir = \"outputs\",\n        ddp_find_unused_parameters=False  # Important for multi-GPU training\n    ),\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T12:29:11.893844Z","iopub.execute_input":"2024-06-17T12:29:11.894243Z","iopub.status.idle":"2024-06-17T12:29:12.031265Z","shell.execute_reply.started":"2024-06-17T12:29:11.894212Z","shell.execute_reply":"2024-06-17T12:29:12.030359Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1965: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use `--hub_token` instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:269: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `dataset_num_proc` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:307: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:397: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n  warnings.warn(\nmax_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 7. Show Current Memory Stats: ","metadata":{}},{"cell_type":"code","source":"#@title Show current memory stats\ngpu_stats = torch.cuda.get_device_properties(0)\nstart_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nmax_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\nprint(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\nprint(f\"{start_gpu_memory} GB of memory reserved.\")","metadata":{"execution":{"iopub.status.busy":"2024-06-17T12:29:15.258944Z","iopub.execute_input":"2024-06-17T12:29:15.259646Z","iopub.status.idle":"2024-06-17T12:29:15.268446Z","shell.execute_reply.started":"2024-06-17T12:29:15.259615Z","shell.execute_reply":"2024-06-17T12:29:15.267122Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"GPU = Tesla T4. Max memory = 14.748 GB.\n3.188 GB of memory reserved.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 8. Training the Model ","metadata":{}},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-17T12:29:18.968998Z","iopub.execute_input":"2024-06-17T12:29:18.969696Z","iopub.status.idle":"2024-06-17T12:33:44.604499Z","shell.execute_reply.started":"2024-06-17T12:29:18.969665Z","shell.execute_reply":"2024-06-17T12:33:44.603472Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n   \\\\   /|    Num examples = 65 | Num Epochs = 8\nO^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n\\        /    Total batch size = 8 | Total steps = 60\n \"-____-\"     Number of trainable parameters = 29,884,416\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [60/60 04:16, Epoch 7/8]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.894200</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2.355100</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2.641200</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2.295000</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>2.670800</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>2.883800</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>3.112300</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>2.781900</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>2.819200</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>2.793500</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>2.458400</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>2.927500</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>2.412600</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>2.604500</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>2.458800</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>2.605900</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>2.741500</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>2.716300</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>3.132600</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>3.227800</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>2.640400</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>2.617400</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>2.473600</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>2.601800</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>2.558200</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>2.758700</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>3.072200</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>2.673500</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>2.629200</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>2.758300</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>2.839700</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>3.305800</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>2.720200</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>3.079900</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>2.342700</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>2.647700</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>2.551000</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>3.338900</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>2.556100</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>2.961800</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>2.810700</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>2.748700</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>2.093600</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>2.502200</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>2.986100</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>2.546000</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>2.498300</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>2.661800</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>3.179200</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>2.457300</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>2.293700</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>3.227500</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>2.417900</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>2.655000</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>2.858500</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>2.563500</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>2.887700</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>2.697400</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>2.749900</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>2.755300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"markdown","source":"## 9. Trained Metrics","metadata":{}},{"cell_type":"code","source":"trainer_stats.metrics","metadata":{"execution":{"iopub.status.busy":"2024-06-17T12:34:24.541536Z","iopub.execute_input":"2024-06-17T12:34:24.542290Z","iopub.status.idle":"2024-06-17T12:34:24.550122Z","shell.execute_reply.started":"2024-06-17T12:34:24.542259Z","shell.execute_reply":"2024-06-17T12:34:24.548821Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"{'train_runtime': 261.794,\n 'train_samples_per_second': 1.834,\n 'train_steps_per_second': 0.229,\n 'total_flos': 5293269845176320.0,\n 'train_loss': 2.720837994416555,\n 'epoch': 7.2727272727272725}"},"metadata":{}}]},{"cell_type":"markdown","source":"## 10. Inference with Fine-tuned Model ","metadata":{}},{"cell_type":"code","source":"# prompt_template = \"How to order\"\nprompt_template = \"How do i check my statusï¼Ÿ\"","metadata":{"execution":{"iopub.status.busy":"2024-06-17T12:35:58.911046Z","iopub.execute_input":"2024-06-17T12:35:58.911428Z","iopub.status.idle":"2024-06-17T12:35:58.917337Z","shell.execute_reply.started":"2024-06-17T12:35:58.911396Z","shell.execute_reply":"2024-06-17T12:35:58.916231Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"FastLanguageModel.for_inference(model) # Enable native 2x faster inference\ninputs = tokenizer(\n[prompt_template], return_tensors = \"pt\").to(\"cuda\")\n\noutputs = model.generate(**inputs, max_new_tokens = 200, use_cache = True)\nprint(tokenizer.batch_decode(outputs)[0])","metadata":{"execution":{"iopub.status.busy":"2024-06-17T12:36:01.367130Z","iopub.execute_input":"2024-06-17T12:36:01.367518Z","iopub.status.idle":"2024-06-17T12:36:13.018749Z","shell.execute_reply.started":"2024-06-17T12:36:01.367485Z","shell.execute_reply":"2024-06-17T12:36:13.017647Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"<s> How do i check my statusï¼Ÿ\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n <Customer>:How do i check my order status? <Agent>:You can check the status of your order by logging into your account and clicking on â€œMy Ordersâ€ in the â€œMy Accountâ€ section.\n\n\n\n\n\n\n\n\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 11. Save the Fine-Tune Model ","metadata":{}},{"cell_type":"code","source":"model.save_pretrained(\"customer_service_lora_model\")\ntokenizer.save_pretrained(\"customer_service_lora_model\")","metadata":{"execution":{"iopub.status.busy":"2024-06-17T12:37:12.895281Z","iopub.execute_input":"2024-06-17T12:37:12.896164Z","iopub.status.idle":"2024-06-17T12:37:13.740692Z","shell.execute_reply.started":"2024-06-17T12:37:12.896132Z","shell.execute_reply":"2024-06-17T12:37:13.739576Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"('customer_service_lora_model/tokenizer_config.json',\n 'customer_service_lora_model/special_tokens_map.json',\n 'customer_service_lora_model/tokenizer.model',\n 'customer_service_lora_model/added_tokens.json',\n 'customer_service_lora_model/tokenizer.json')"},"metadata":{}}]},{"cell_type":"markdown","source":"## 12. Push to HuggingFace","metadata":{}},{"cell_type":"code","source":"# Push to Hugging Face\nmodel_name = \"customer_service_lora_model\"  # Name of your model on the Hugging Face Model Hub\nuser_name = \"yourname\"  # Replace with your Hugging Face username\n\n\n# Use the `push_to_hub` method to upload the model and tokenizer\nmodel.push_to_hub(model_name)\ntokenizer.push_to_hub(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T12:54:39.985013Z","iopub.execute_input":"2024-06-17T12:54:39.985751Z","iopub.status.idle":"2024-06-17T12:54:39.990965Z","shell.execute_reply.started":"2024-06-17T12:54:39.985718Z","shell.execute_reply":"2024-06-17T12:54:39.990032Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}